{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eda2b09-9afd-4837-be71-17a2af3fde14",
   "metadata": {},
   "source": [
    "# Mtb Subnetwork Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770f30d5-debc-445e-9fbb-aef3918e5cfa",
   "metadata": {},
   "source": [
    "## Analysis of Healthy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71d2db6b-8700-4bd6-b50c-23aabdb308cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff5dd8c-5b22-4cc3-a869-2ebb288b51a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import graph\n",
    "file = open(\"../Data/Macrophage_protein_network_with_attributes.pkl\", \"rb\")\n",
    "G = nx.read_gpickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e0a4ee-3c10-46f7-aad6-e7ce462f57d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goal =  Create and save graph object of graph subnetwork of just MTB neighbors's neighbors (second degree)\n",
    "\n",
    "#Function for getting neighborhood nodes\n",
    "def second_neighbors(graph, node) -> list:\n",
    "    \"\"\"Takes a graph and a node of choice and returns a list of the unique neighborhood nodes of the second degree for the given node,including the given node\"\"\"\n",
    "    node = str(node)\n",
    "    neighbor_list = []\n",
    "    neighbor_list.append(node)\n",
    "    for first_neighbor in graph.neighbors(node):\n",
    "        neighbor_list.append(first_neighbor)\n",
    "        for second_neighbor in graph.neighbors(first_neighbor):\n",
    "            if second_neighbor != node:\n",
    "                neighbor_list.append(second_neighbor)\n",
    "    #Filter unqiue\n",
    "    return_list = [] \n",
    "    for i in neighbor_list:\n",
    "        if i not in return_list:\n",
    "            return_list.append(i)\n",
    "    \n",
    "    return(neighbor_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f237b5c2-dc05-4b1b-8187-671c171a3f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Mtb interactions\n",
    "mtb_paper_edges = [\n",
    "('Q7L591', 'Apa'),\n",
    "('P50552', 'Apa'),\n",
    "('Q9UI08', 'Apa'),\n",
    "('Q15654', 'Apa'),\n",
    "('Q16543', 'LpqR'),\n",
    "('Q15287', 'Rv1827'),\n",
    "('Q9C005', 'Rv1075C'),\n",
    "('Q9C005', 'Rv1074c'),\n",
    "('Q14847', 'Rv3033'),\n",
    "('Q14005', 'Rv3033'),\n",
    "('P22681', 'LpqN'),\n",
    "('P20339', 'TB8.4'),\n",
    "('P51610', 'Rv3668c'),\n",
    "('P12956', 'EspR'),\n",
    "('P62820', 'ESAT6'),\n",
    "('Q15233', 'Apa'),\n",
    "('Q07812', 'PE25'),\n",
    "('O95466', 'LpqN'),\n",
    "('Q9NXV2', 'LpqN'),\n",
    "('Q15154', 'Rv1827'),\n",
    "('Q01130', 'Rv1827'),\n",
    "('O60488', 'PE25')]\n",
    "\n",
    "mtb_node_names = [\n",
    "'Rv3033',\n",
    "'Apa',\n",
    "'PE25',\n",
    "'Rv1827',\n",
    "'LpqN',\n",
    "'Rv1075C',\n",
    "'Rv1074c',\n",
    "'LpqR',\n",
    "'EspR',\n",
    "'TB8.4',\n",
    "'Rv3668c',\n",
    "'ESAT6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8cab4bc-da01-4d35-9d30-5e09f6eac6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #write list to file \n",
    "# import csv\n",
    "# with open(\"../Data/mtb_interactions.csv\",\"w\") as file:\n",
    "#     csv_out = csv.writer(file)\n",
    "#     csv_out.writerows(mtb_paper_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d3830ce0-5927-48b7-9c10-a3ff0294a689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph named 'Mtb Healthy Macrophage Sub-network' with 84 nodes and 97 edges\n"
     ]
    }
   ],
   "source": [
    "#Given list of mtb-human protein interactions, pull out the the list of human proteins:\n",
    "mtb_human_prot_list = []\n",
    "for pair in mtb_paper_edges: #need to change to given list\n",
    "    if pair[0] in G.nodes():\n",
    "        mtb_human_prot_list.append(pair[0])\n",
    "\n",
    "if len(mtb_human_prot_list) != len(mtb_paper_edges): #just a test\n",
    "    print(\"something is wrong, list lengths arent equal\")\n",
    "\n",
    "\n",
    "# aggregate node list of all mtb interactions and their neighbor\n",
    "\n",
    "def mtb_healthy_neighborhood(lst,graph) -> list:\n",
    "    \"\"\"Function takes a list of known mtb interactions and a healthy network graph and compiles\n",
    "    a list of all nodes of the first/second degree in the healthy network that mtb interacts with\"\"\"\n",
    "    tmp_second_degree_community = []\n",
    "    for item in lst:\n",
    "        tmp = item \n",
    "        #tmp_neighborhood_list = second_neighbors(G, tmp) ##unblock this for second degree\n",
    "        tmp_neighborhood_list = list(G.neighbors(tmp)) ##unblock this for first degree\n",
    "        tmp_second_degree_community += tmp_neighborhood_list #merge neighborhood list with community list\n",
    "        tmp_second_degree_community.append(tmp)\n",
    "    #Remove duplicates in community list \n",
    "    second_degree_community = [] \n",
    "    for i in tmp_second_degree_community:\n",
    "        if i not in second_degree_community:\n",
    "            second_degree_community.append(i)\n",
    "    return(second_degree_community)\n",
    "\n",
    "def edge_puller(node_list, graph) -> list:\n",
    "    \"\"\"Function inputs a list of nodes and a graph and returns a list of all edges containing those nodes\"\"\"\n",
    "    edge_list = []\n",
    "    for edge in graph.edges():\n",
    "        #if (edge[0] in node_list) or (edge[1] in node_list): ##unblock this for edges that need only 1 pair\n",
    "        if (edge[0] in node_list) and (edge[1] in node_list): ##unblock this for restriction of edges\n",
    "            edge_list.append(edge)\n",
    "    return(edge_list)\n",
    "            \n",
    "#Call function\n",
    "healthy_neighborhood_nodes = mtb_healthy_neighborhood(mtb_human_prot_list,G)\n",
    "\n",
    "#Aggregate neighborhood edges from main graph:\n",
    "healthy_neighborhood_edges = edge_puller(healthy_neighborhood_nodes,G)\n",
    "\n",
    "\n",
    "#Create and save graph\n",
    "Gx = nx.Graph(name = \"Mtb Healthy Macrophage Sub-network\")\n",
    "Gx.add_edges_from(healthy_neighborhood_edges)\n",
    "\n",
    "\n",
    "#Add attributes to new graph which got lost in the transfer process\n",
    "for node in Gx.nodes():\n",
    "    for attribute in list(G.nodes['P20333'].keys()): #gets list of all atrributes\n",
    "        Gx.nodes[node][attribute] = G.nodes[node][attribute]\n",
    "        \n",
    "\n",
    "\n",
    "#Examine Gx\n",
    "print(Gx)\n",
    "\n",
    "#save graph\n",
    "nx.write_gpickle(Gx, '../Data/Macrophage_healthy_Mtb_sub_protein_network_with_attributes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "98c3885f-b2d6-47bc-b1ba-1dab9aba3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create color mapping dictionary where subcell location = key and color = value\n",
    "#Reserved colors (not used) = lime, yellow, blue\n",
    "color_dict = {\n",
    "    \"Apical cell membrane\":'grey', \n",
    "    \"Basolateral cell membrane\":'darkgray',\n",
    "    \"Cell junction\":'lightgrey',\n",
    "    \"Cell membrane\":'gainsboro',\n",
    "    \"Cell projection\":'rosybrown',\n",
    "    \"Cell surface\":'lightcoral',\n",
    "    \"Chromosome\":'brown',\n",
    "    \"Cytoplasm\":'maroon',\n",
    "    \"Cytoplasmic granule\":'red',\n",
    "    \"Cytoplasmic granule membrane\":'mistyrose',\n",
    "    \"Cytoplasmic vesicle\":'tomato',\n",
    "    \"Cytoplasmic vesicle membrane\":'darksalmon',\n",
    "    \"Early endosome\":'sienna',\n",
    "    \"Early endosome membrane\":'chocolate',\n",
    "    \"Endomembrane system\":'saddlebrown',\n",
    "    \"Endoplasmic reticulum\":'sandybrown',\n",
    "    \"Endoplasmic reticulum lumen\":'peachpuff',\n",
    "    \"Endoplasmic reticulum membrane\":'linen',\n",
    "    \"Endoplasmic reticulum-Golgi intermediate compartment membrane\":'bisque',\n",
    "    \"Endosome membrane\":'darkorange',\n",
    "    \"Golgi apparatus\":'burlywood',\n",
    "    \"Golgi apparatus membrane\":'tan',\n",
    "    \"Golgi outpost\":'papayawhip',\n",
    "    \"Host cell membrane\":'orange',\n",
    "    \"Host cytoplasm\":'wheat',\n",
    "    \"Host endoplasmic reticulum membrane\":'moccasin',\n",
    "    \"Host membrane\":'blanchedalmond',\n",
    "    \"Host nucleus\":'darkgoldenrod',\n",
    "    \"Host nucleus inner membrane\":'goldenrod',\n",
    "    \"Late endosome membrane\":'cornsilk',\n",
    "    \"Lysosome\":'gold',\n",
    "    \"Lysosome membrane\":'lemonchiffon',\n",
    "    \"Membrane\":'darkkhaki',\n",
    "    \"Microsome\":'lightyellow',\n",
    "    \"Microsome membrane\":'olivedrab',\n",
    "    \"Midbody\":'beige',\n",
    "    \"Mitochondrion\":'olivedrab',\n",
    "    \"Mitochondrion inner membrane\":'yellowgreen',\n",
    "    \"Mitochondrion intermembrane space\":'darkolivegreen',\n",
    "    \"Mitochondrion matrix\":'darkseagreen',\n",
    "    \"Mitochondrion membrane\":'palegreen',\n",
    "    \"Mitochondrion outer membrane\":'forestgreen',\n",
    "    \"Myelin membrane\":'darkgreen',\n",
    "    \"Nucleus\":'deepskyblue',\n",
    "    \"Nucleus envelope\":'steelblue',\n",
    "    \"Nucleus inner membrane\":'lightblue',\n",
    "    \"Nucleus matrix\":'cadetblue',\n",
    "    \"Nucleus membrane\":'cyan',\n",
    "    \"Nucleus outer membrane\":'darkcyan',\n",
    "    \"Nucleus speckle\":'darkturquoise',\n",
    "    \"Perikaryon\":'slategrey',\n",
    "    \"Peroxisome\":'aquamarine',\n",
    "    \"Peroxisome membrane\":'mediumaquamarine',\n",
    "    \"Photoreceptor inner segment\":'cornflowerblue',\n",
    "    \"Recycling endosome\":'navy',\n",
    "    \"Recycling endosome membrane\":'mediumblue',\n",
    "    \"Rough endoplasmic reticulum\":'blueviolet',\n",
    "    \"Rough endoplasmic reticulum membrane\":'indigo',\n",
    "    \"Sarcoplasmic reticulum lumen\":'plum',\n",
    "    \"Secreted\":'fuchsia',\n",
    "    \"Unknown\":'black',\n",
    "    \"Vacuole membrane\":'slateblue',\n",
    "    \"Virion\":'crimson',\n",
    "    \"Virion membrane\":'palevioletred',\n",
    "    \"Virion tegument\":'lightpink'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fbe589cb-d7d4-42aa-a82d-b21560613ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q7L591', 'P50552', 'Q9UI08', 'Q15654', 'Q16543', 'Q15287', 'Q9C005', 'Q9C005', 'Q14847', 'Q14005', 'P22681', 'P20339', 'P51610', 'P12956', 'P62820', 'Q15233', 'Q07812', 'O95466', 'Q9NXV2', 'Q15154', 'Q01130', 'O60488']\n"
     ]
    }
   ],
   "source": [
    "print(mtb_human_prot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25cb948b-2164-434b-a28b-1f149259516d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Gx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6733/3257120725.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#setting x and y coordinates for nodes and edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspring_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#setting color map for attributes. Nodes that MTB interacts with are colored lime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Gx' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graph the subnetwork\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#set fig dimensions\n",
    "plt.figure(figsize =(15,15))\n",
    "\n",
    "#setting x and y coordinates for nodes and edges\n",
    "pos = nx.spring_layout(Gx, iterations=20, seed = 15)\n",
    "\n",
    "#setting color map for attributes. Nodes that MTB interacts with are colored lime\n",
    "color_map =[]\n",
    "for node in Gx.nodes():\n",
    "    location = Gx.nodes[node]['Subcellular_location_[CC]']\n",
    "    if node in mtb_human_prot_list:\n",
    "        color_map.append('lime')\n",
    "    else:\n",
    "        color_map.append(color_dict[location])\n",
    " \n",
    "        \n",
    "\n",
    "#Draw nodes w/ color map\n",
    "nx.draw_networkx_nodes(Gx, \n",
    "                       pos, \n",
    "                       node_size=150,\n",
    "                       alpha = 0.75,\n",
    "                       nodelist = Gx.nodes(), \n",
    "                       node_color = color_map,\n",
    "                       with_labels = True\n",
    "                      )\n",
    "\n",
    "\n",
    "#Draw Edges        \n",
    "nx.draw_networkx_edges(Gx, pos)\n",
    "\n",
    "#Plot Labels\n",
    "name = \"Subnetwork of macrophage proteins shown to interact with Mtb\"\n",
    "plt.title((name), fontdict = {'fontsize': 25, \"color\":'black'})\n",
    "plt.legend(scatterpoints=1)\n",
    "\n",
    "#####################Need to figure out how to add color legend \n",
    "# Scatter plot so I can have a legend\n",
    "unique_subcellular_sub = list(set([part[0] for node,part in Gx.nodes(data='Subcellular_location_[CC]')]))\n",
    "for v in unique_subcellular_sub:\n",
    "    plt.scatter([],[], c=c, label='{}'.format(v))\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f85e8a-8b23-4466-86eb-b385dcb3e0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e9fa59f4-cb6e-46fc-9207-4d01e8f1b593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 84 nodes and 97 edges\n",
      "General graph features = None\n",
      "Graph not connected, no graph center can not be calculated\n",
      "Graph not connected, Diameter can bot be calculated\n",
      "Graph not connected, Radius can bot be calculated\n",
      "The Average Degree of our network is 1.15. The average degree of a network refers to the average number of edges that exist for each node.\n",
      "The Density of our graph is 0.001. Density is a measure of how many ties between nodes exist compared to how many are possible.\n",
      "The average clustering coefficient of our graph is 0.0573. The clustering coefficient ranges from 0-1 and is a measure of the ratio of connections for each node observed versus what is possible \n",
      "Is the graph fully connected? False\n",
      "Number of connected components = 7\n",
      "Number of isolates = 0\n"
     ]
    }
   ],
   "source": [
    "#Graph Features of subnetwork\n",
    "#Eccentricity of a node is the maximum distance from that node to all other nodes in the graph\n",
    "\n",
    "#Graph Length\n",
    "print(\"General graph features = {}\".format(print(Gx)))\n",
    "\n",
    "#Graph Center (center is the set of nodes with eccentricity equal to radius)\n",
    "try: \n",
    "    print(\"Graph center = {}\".format(nx.center(Gx)))\n",
    "except:\n",
    "    print(\"Graph not connected, no graph center can not be calculated\")\n",
    "\n",
    "\n",
    "#Graph Diameter (diameter is maximum eccentricity)\n",
    "try:\n",
    "    print(\"Graph diameter = {}\".format(nx.diameter(Gx)))\n",
    "except:\n",
    "    print(\"Graph not connected, Diameter can bot be calculated\")\n",
    "\n",
    "\n",
    "#Graph Radius (minimum eccentricity)\n",
    "try:\n",
    "    print(\"Graph Radius = {}\".format(nx.radius(Gx)))\n",
    "except:\n",
    "    print(\"Graph not connected, Radius can bot be calculated\")\n",
    "      \n",
    "#Average Degree\n",
    "total_edges = len(Gx.edges())\n",
    "total_nodes = len(Gx.nodes())\n",
    "Avg_degree = total_edges/total_nodes\n",
    "print(\"The Average Degree of our network is {}. The average degree of a network refers to the average number of edges that exist for each node.\".format(round(Avg_degree,2)))\n",
    "\n",
    "#Density of graph\n",
    "print(\"The Density of our graph is {}. Density is a measure of how many ties between nodes exist compared to how many are possible.\".format(round(nx.density(G),4)))\n",
    "\n",
    "#Average clustering coefficient\n",
    "print(\"The average clustering coefficient of our graph is {}. The clustering coefficient ranges from 0-1 and is a measure of the ratio of connections for each node observed versus what is possible \".format(round(nx.average_clustering(Gx),4)))\n",
    "\n",
    "#Is the graph fully connected?\n",
    "print(\"Is the graph fully connected? {}\".format(nx.is_connected(Gx)))\n",
    "\n",
    "#Number of connected components:\n",
    "print(\"Number of connected components = {}\".format(nx.number_connected_components(Gx)))\n",
    "\n",
    "#Number of Isolates (no neighbors)\n",
    "isolates = len(list(nx.isolates(Gx)))\n",
    "print(\"Number of isolates = {}\".format(isolates))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6ccf35d0-22c4-4fe9-989a-bbf0065c3e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of top 5% most 'betweenness' central nodes and their corresponding centrality values:\n",
      "Q7L591 :\t 0.4941223663527514\n",
      "O95466 :\t 0.2515112715671048\n",
      "P10412 :\t 0.21006091730452597\n",
      "P12956 :\t 0.13535442583341498\n",
      "List of top 5% most 'closeness' central nodes and their corresponding centrality value:\n",
      "Q7L591 :\t 0.3621849360632715\n",
      "P10412 :\t 0.31739862676512504\n",
      "O95466 :\t 0.28939286557996696\n",
      "P40763 :\t 0.2824695912837955\n",
      "List of top 5% most 'degree' central nodes and their corresponding centrality value:\n",
      "Q7L591 :\t 0.3734939759036145\n",
      "O95466 :\t 0.08433734939759037\n",
      "P22681 :\t 0.07228915662650603\n",
      "P12956 :\t 0.07228915662650603\n"
     ]
    }
   ],
   "source": [
    "#Centrality detection of Subnetwork\n",
    "\n",
    "#Edge betweenness (better at finding bottlenecks)\n",
    "betweenness_centralities = nx.betweenness_centrality(Gx) #dictionary of values\n",
    "betweenness_sorted = dict(sorted(betweenness_centralities.items(), reverse = True, key=lambda x:x[1])) #sort it so highest centrality are at top\n",
    "top_vals_betweenness = {k: betweenness_sorted[k] for k in list(betweenness_sorted)[:int((len(betweenness_sorted)*0.05))]}  #Dict of top 5% of nodes\n",
    "print(\"List of top 5% most 'betweenness' central nodes and their corresponding centrality values:\")\n",
    "for i in top_vals_betweenness:\n",
    "    print(i, ':\\t', top_vals_betweenness[i])\n",
    "\n",
    "\n",
    "#Closeness\n",
    "Closeness_centralities = nx.closeness_centrality(Gx)\n",
    "Closeness_sorted = dict(sorted(Closeness_centralities.items(), reverse = True, key=lambda x:x[1]))\n",
    "top_vals_closeness =  {k: Closeness_sorted[k] for k in list(Closeness_sorted)[:int((len(Closeness_sorted)*0.05))]}  #Dict of top 5% of nodes\n",
    "print(\"List of top 5% most 'closeness' central nodes and their corresponding centrality value:\")\n",
    "for i in top_vals_closeness:\n",
    "    print(i, ':\\t', top_vals_closeness[i])\n",
    "\n",
    "\n",
    "#Degree centrality \n",
    "Degree_centralities = nx.degree_centrality(Gx)\n",
    "Degree_sorted = dict(sorted(Degree_centralities.items(), reverse = True, key=lambda x:x[1])) #sort it so highest centrality are at top\n",
    "top_vals_degree =  {k: Degree_sorted[k] for k in list(Degree_sorted)[:int((len(Degree_sorted)*0.05))]}  #Dict of top 5% of nodes\n",
    "print(\"List of top 5% most 'degree' central nodes and their corresponding centrality value:\")\n",
    "for i in top_vals_degree:\n",
    "    print(i, ':\\t', top_vals_degree[i])\n",
    "\n",
    "\n",
    "\n",
    "#Graph the network, labeling and highlighting the top 5% central nodes for each method ######NEED TO DO THIS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c038eb79-ffeb-4034-bc4a-b73dfa063f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communities detected by the Louvain algo = 12\n",
      "Communities detected by the FastGreedy algo = 13\n",
      "Communities detected by the walktrap algo = 16\n",
      "Communities detected by the edgebetweenness algo = 8\n"
     ]
    }
   ],
   "source": [
    "#Community Detection of Subnetwork\n",
    "\n",
    "#Louvain method\n",
    "import community\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "\n",
    "healthy_sub_louvain = community.best_partition(Gx, random_state=0)  #This object returned is a dictionary containing the nodes of graph G as keys, and the community number that node belongs to as the value\n",
    "\n",
    "\n",
    "#Changing structure of dictionary so that keys = community assignment, and values = list of nodes. This will make it easier for later use\n",
    "sub_louvain_best_partition_working = {}\n",
    "for key,value in healthy_sub_louvain.items():\n",
    "    if value in sub_louvain_best_partition_working.keys():\n",
    "        sub_louvain_best_partition_working[value].append(key) \n",
    "    else:\n",
    "        sub_louvain_best_partition_working[value] = []    \n",
    "\n",
    "#Sorting dictionary so keys are in ascending order:\n",
    "sub_louvain_partition = {}\n",
    "sorted_key_list = list(sub_louvain_best_partition_working.keys())\n",
    "sorted_key_list.sort()\n",
    "\n",
    "for i in sorted_key_list:\n",
    "    sub_louvain_partition[i] = sub_louvain_best_partition_working[i]\n",
    "        \n",
    "#Determining how many communities constitute the 'best partition'. i.e how many communities did louvain find?\n",
    "print(\"Communities detected by the Louvain algo = {}\".format(len(list(sub_louvain_partition.keys()))))\n",
    "\n",
    "#FastGreedy--------------------------------\n",
    "sub_fastgreedy_partition_working = list(greedy_modularity_communities(Gx)) #The object returned is a list of sets of nodes, each for a different community\n",
    "sub_fastgreedy_partition = {i:sub_fastgreedy_partition_working[i] for i in range(len(sub_fastgreedy_partition_working))} #create dict with same structure\n",
    "print(\"Communities detected by the FastGreedy algo = {}\".format(len(sub_fastgreedy_partition)))\n",
    "\n",
    "#WalkTrap--------------------------------------\n",
    "from cdlib import algorithms\n",
    "from cdlib import readwrite\n",
    "import csv\n",
    "#sub_walktrap_partition = algorithms.walktrap(Gx) #The object returned is a NodeClusterint object   ##unblock this to rerun algo\n",
    "#readwrite.write_community_csv(sub_walktrap_partition, \"../Data/sub_healthy_walktrap.csv\") #save object as csv file ##unblock this to resave object\n",
    "sub_walktrap_partition = {} \n",
    "with open(\"../Data/sub_healthy_walktrap.csv\") as file:  #read csv file and create community dict\n",
    "    file_lines = csv.reader(file, delimiter=',')\n",
    "    lst = []\n",
    "    for line in file_lines:\n",
    "        lst.append(line)\n",
    "    for i in range(len(lst)):\n",
    "        sub_walktrap_partition[i] = lst[i]\n",
    "print(\"Communities detected by the walktrap algo = {}\".format(len(sub_walktrap_partition.keys())))\n",
    "\n",
    "\n",
    "#Edge_betweeness--------------------------------\n",
    "#sub_edgebetweenness_partition = algorithms.girvan_newman(Gx,level=1,) #The object returned is a list of sets of nodes, each for a different community  ##unblock this to rerun algo\n",
    "#readwrite.write_community_csv(sub_edgebetweenness_partition, \"../Data/sub_healthy_edgebetweenness.csv\") #save object as csv file ##unblock this to resave object  ##unblock this to resave object\n",
    "sub_edgebetweenness_partition = {} \n",
    "with open(\"../Data/sub_healthy_edgebetweenness.csv\") as file:  #read csv file and create community dict\n",
    "    file_lines = csv.reader(file, delimiter=',')\n",
    "    lst = []\n",
    "    for line in file_lines:\n",
    "        lst.append(line)\n",
    "    for i in range(len(lst)):\n",
    "        sub_edgebetweenness_partition[i] = lst[i]\n",
    "print(\"Communities detected by the edgebetweenness algo = {}\".format(len(sub_edgebetweenness_partition.keys())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92227c5-512e-44d3-a56b-c5fbe6286cda",
   "metadata": {},
   "source": [
    "## Idea - 4 panel graph, with communities detected by each method to compare? Need to figure out best way to graph community structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ed8a89cf-6e82-4c82-91fb-dcac5a927fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<cdlib.classes.node_clustering.NodeClustering object at 0x7f9d2ca74310>\n"
     ]
    }
   ],
   "source": [
    "print(sub_edgebetweenness_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "93f6b394-ced1-49f9-bf58-3e8cde084318",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NodeClustering' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25202/852382166.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msub_edgebetweenness_partition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NodeClustering' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "sub_edgebetweenness_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b866ba9e-b1da-425c-a691-7f931172c78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Q7L591', 'Apa'), ('P50552', 'Apa'), ('Q9UI08', 'Apa'), ('Q15654', 'Apa'), ('Q16543', 'LpqR'), ('Q15287', 'Rv1827'), ('Q9C005', 'Rv1075C'), ('Q9C005', 'Rv1074c'), ('Q14847', 'Rv3033'), ('Q14005', 'Rv3033'), ('P22681', 'LpqN'), ('P20339', 'TB8.4'), ('P51610', 'Rv3668c'), ('P12956', 'EspR'), ('P62820', 'ESAT6'), ('Q15233', 'Apa'), ('Q07812', 'PE25'), ('O95466', 'LpqN'), ('Q9NXV2', 'LpqN'), ('Q15154', 'Rv1827'), ('Q01130', 'Rv1827'), ('O60488', 'PE25')]\n"
     ]
    }
   ],
   "source": [
    "print(mtb_paper_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ab885-8a05-484e-967f-74de290784b8",
   "metadata": {},
   "source": [
    "# Analysis of Diseased Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ee798dc0-1ede-4b5f-a79e-73d13a976721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 84 nodes and 97 edges\n",
      "Graph named 'Mtb Diseased Macrophage Sub-network' with 96 nodes and 119 edges\n"
     ]
    }
   ],
   "source": [
    "#Creating diseased subnetwork\n",
    "print(Gx)\n",
    "\n",
    "Gz = nx.Graph(name = \"Mtb Diseased Macrophage Sub-network\" )\n",
    "Gz.add_edges_from(Gx.edges())\n",
    "Gz.add_edges_from(mtb_paper_edges)\n",
    "print(Gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "f1df01c5-46e4-4826-b492-a1c768643641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General graph features = Graph named 'Mtb Diseased Macrophage Sub-network' with 96 nodes and 119 edges\n",
      "Graph not connected, no graph center can not be calculated\n",
      "Graph not connected, Diameter can bot be calculated\n",
      "Graph not connected, Radius can bot be calculated\n",
      "The Average Degree of our network is 1.24. The average degree of a network refers to the average number of edges that exist for each node.\n",
      "The Density of our graph is 0.0261. Density is a measure of how many ties between nodes exist compared to how many are possible.\n",
      "The average clustering coefficient of our graph is 0.0499. The clustering coefficient ranges from 0-1 and is a measure of the ratio of connections for each node observed versus what is possible \n",
      "Is the graph fully connected? False\n",
      "Number of connected components = 4\n",
      "Number of isolates = 0\n"
     ]
    }
   ],
   "source": [
    "#Graph Features of diseased subnetwork\n",
    "#Graph Features of subnetwork\n",
    "#Eccentricity of a node is the maximum distance from that node to all other nodes in the graph\n",
    "\n",
    "#Graph Length\n",
    "print(\"General graph features = {}\".format(Gz))\n",
    "\n",
    "#Graph Center (center is the set of nodes with eccentricity equal to radius)\n",
    "try: \n",
    "    print(\"Graph center = {}\".format(nx.center(Gz)))\n",
    "except:\n",
    "    print(\"Graph not connected, no graph center can not be calculated\")\n",
    "\n",
    "\n",
    "#Graph Diameter (diameter is maximum eccentricity)\n",
    "try:\n",
    "    print(\"Graph diameter = {}\".format(nx.diameter(Gz)))\n",
    "except:\n",
    "    print(\"Graph not connected, Diameter can bot be calculated\")\n",
    "\n",
    "\n",
    "#Graph Radius (minimum eccentricity)\n",
    "try:\n",
    "    print(\"Graph Radius = {}\".format(nx.radius(Gz)))\n",
    "except:\n",
    "    print(\"Graph not connected, Radius can bot be calculated\")\n",
    "      \n",
    "#Average Degree\n",
    "total_edges = len(Gz.edges())\n",
    "total_nodes = len(Gz.nodes())\n",
    "Avg_degree = total_edges/total_nodes\n",
    "print(\"The Average Degree of our network is {}. The average degree of a network refers to the average number of edges that exist for each node.\".format(round(Avg_degree,2)))\n",
    "\n",
    "#Density of graph\n",
    "print(\"The Density of our graph is {}. Density is a measure of how many ties between nodes exist compared to how many are possible.\".format(round(nx.density(Gz),4)))\n",
    "\n",
    "#Average clustering coefficient\n",
    "print(\"The average clustering coefficient of our graph is {}. The clustering coefficient ranges from 0-1 and is a measure of the ratio of connections for each node observed versus what is possible \".format(round(nx.average_clustering(Gz),4)))\n",
    "\n",
    "#Is the graph fully connected?\n",
    "print(\"Is the graph fully connected? {}\".format(nx.is_connected(Gz)))\n",
    "\n",
    "#Number of connected components:\n",
    "print(\"Number of connected components = {}\".format(nx.number_connected_components(Gz)))\n",
    "\n",
    "#Number of Isolates (no neighbors)\n",
    "isolates = len(list(nx.isolates(Gz)))\n",
    "print(\"Number of isolates = {}\".format(isolates))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "87f508b7-1f85-48f2-b812-2fdfd2b04a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3da86709-e6fb-44cc-b49a-40e355b26faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of top 5% most 'betweenness' central nodes and their corresponding centrality values:\n",
      "Q7L591 :\t 0.4855827512042517\n",
      "O95466 :\t 0.2719860822268439\n",
      "P10412 :\t 0.2182183295117228\n",
      "P12956 :\t 0.12027782221511225\n",
      "List of top 5% most 'closeness' central nodes and their corresponding centrality value:\n",
      "Q7L591 :\t 0.3503178235443682\n",
      "P10412 :\t 0.32229239766081874\n",
      "O95466 :\t 0.30089539200698845\n",
      "P40763 :\t 0.27572543526115667\n",
      "List of top 5% most 'degree' central nodes and their corresponding centrality value:\n",
      "Q7L591 :\t 0.3368421052631579\n",
      "O95466 :\t 0.08421052631578947\n",
      "P22681 :\t 0.07368421052631578\n",
      "P12956 :\t 0.07368421052631578\n"
     ]
    }
   ],
   "source": [
    "#Centrality Detection of diseased subnetwork\n",
    "\n",
    "#Edge betweenness (better at finding bottlenecks)\n",
    "betweenness_centralities = nx.betweenness_centrality(Gz) #dictionary of values\n",
    "betweenness_sorted = dict(sorted(betweenness_centralities.items(), reverse = True, key=lambda x:x[1])) #sort it so highest centrality are at top\n",
    "top_vals_betweenness = {k: betweenness_sorted[k] for k in list(betweenness_sorted)[:int((len(betweenness_sorted)*0.05))]}  #Dict of top 5% of nodes\n",
    "print(\"List of top 5% most 'betweenness' central nodes and their corresponding centrality values:\")\n",
    "for i in top_vals_betweenness:\n",
    "    print(i, ':\\t', top_vals_betweenness[i])\n",
    "\n",
    "\n",
    "#Closeness\n",
    "Closeness_centralities = nx.closeness_centrality(Gz)\n",
    "Closeness_sorted = dict(sorted(Closeness_centralities.items(), reverse = True, key=lambda x:x[1]))\n",
    "top_vals_closeness =  {k: Closeness_sorted[k] for k in list(Closeness_sorted)[:int((len(Closeness_sorted)*0.05))]}  #Dict of top 5% of nodes\n",
    "print(\"List of top 5% most 'closeness' central nodes and their corresponding centrality value:\")\n",
    "for i in top_vals_closeness:\n",
    "    print(i, ':\\t', top_vals_closeness[i])\n",
    "\n",
    "\n",
    "#Degree centrality \n",
    "Degree_centralities = nx.degree_centrality(Gz)\n",
    "Degree_sorted = dict(sorted(Degree_centralities.items(), reverse = True, key=lambda x:x[1])) #sort it so highest centrality are at top\n",
    "top_vals_degree =  {k: Degree_sorted[k] for k in list(Degree_sorted)[:int((len(Degree_sorted)*0.05))]}  #Dict of top 5% of nodes\n",
    "print(\"List of top 5% most 'degree' central nodes and their corresponding centrality value:\")\n",
    "for i in top_vals_degree:\n",
    "    print(i, ':\\t', top_vals_degree[i])\n",
    "\n",
    "\n",
    "\n",
    "#Graph the network, labeling and highlighting the top 5% central nodes for each method ######NEED TO DO THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "45e17158-4d8b-4f99-9ea8-ee6cdd1895a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communities detected by the Louvain algo = 9\n",
      "Communities detected by the FastGreedy algo = 10\n",
      "Communities detected by the walktrap algo = 16\n",
      "Communities detected by the edgebetweenness algo = 5\n"
     ]
    }
   ],
   "source": [
    "#Community Detection of diseased subnetwork\n",
    "\n",
    "#Louvain method\n",
    "import community\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "\n",
    "healthy_sub_louvain = community.best_partition(Gz, random_state=0)  #This object returned is a dictionary containing the nodes of graph G as keys, and the community number that node belongs to as the value\n",
    "\n",
    "\n",
    "#Changing structure of dictionary so that keys = community assignment, and values = list of nodes. This will make it easier for later use\n",
    "sub_louvain_best_partition_working = {}\n",
    "for key,value in healthy_sub_louvain.items():\n",
    "    if value in sub_louvain_best_partition_working.keys():\n",
    "        sub_louvain_best_partition_working[value].append(key) \n",
    "    else:\n",
    "        sub_louvain_best_partition_working[value] = []    \n",
    "\n",
    "#Sorting dictionary so keys are in ascending order:\n",
    "sub_louvain_partition = {}\n",
    "sorted_key_list = list(sub_louvain_best_partition_working.keys())\n",
    "sorted_key_list.sort()\n",
    "\n",
    "for i in sorted_key_list:\n",
    "    sub_louvain_partition[i] = sub_louvain_best_partition_working[i]\n",
    "        \n",
    "#Determining how many communities constitute the 'best partition'. i.e how many communities did louvain find?\n",
    "print(\"Communities detected by the Louvain algo = {}\".format(len(list(sub_louvain_partition.keys()))))\n",
    "\n",
    "#FastGreedy--------------------------------\n",
    "sub_fastgreedy_partition_working = list(greedy_modularity_communities(Gz)) #The object returned is a list of sets of nodes, each for a different community\n",
    "sub_fastgreedy_partition = {i:sub_fastgreedy_partition_working[i] for i in range(len(sub_fastgreedy_partition_working))} #create dict with same structure\n",
    "print(\"Communities detected by the FastGreedy algo = {}\".format(len(sub_fastgreedy_partition)))\n",
    "\n",
    "#WalkTrap--------------------------------------\n",
    "from cdlib import algorithms\n",
    "from cdlib import readwrite\n",
    "import csv\n",
    "#sub_walktrap_partition = algorithms.walktrap(Gz) #The object returned is a NodeClusterint object   ##unblock this to rerun algo\n",
    "#readwrite.write_community_csv(sub_walktrap_partition, \"../Data/sub_diseased_walktrap.csv\") #save object as csv file ##unblock this to resave object\n",
    "sub_walktrap_partition = {} \n",
    "with open(\"../Data/sub_diseased_walktrap.csv\") as file:  #read csv file and create community dict\n",
    "    file_lines = csv.reader(file, delimiter=',')\n",
    "    lst = []\n",
    "    for line in file_lines:\n",
    "        lst.append(line)\n",
    "    for i in range(len(lst)):\n",
    "        sub_walktrap_partition[i] = lst[i]\n",
    "print(\"Communities detected by the walktrap algo = {}\".format(len(sub_walktrap_partition.keys())))\n",
    "\n",
    "\n",
    "#Edge_betweeness--------------------------------\n",
    "#sub_edgebetweenness_partition = algorithms.girvan_newman(Gz,level=1,) #The object returned is a list of sets of nodes, each for a different community  ##unblock this to rerun algo\n",
    "#readwrite.write_community_csv(sub_edgebetweenness_partition, \"../Data/sub_diseased_edgebetweenness.csv\") #save object as csv file ##unblock this to resave object  ##unblock this to resave object\n",
    "sub_edgebetweenness_partition = {} \n",
    "with open(\"../Data/sub_diseased_edgebetweenness.csv\") as file:  #read csv file and create community dict\n",
    "    file_lines = csv.reader(file, delimiter=',')\n",
    "    lst = []\n",
    "    for line in file_lines:\n",
    "        lst.append(line)\n",
    "    for i in range(len(lst)):\n",
    "        sub_edgebetweenness_partition[i] = lst[i]\n",
    "print(\"Communities detected by the edgebetweenness algo = {}\".format(len(sub_edgebetweenness_partition.keys())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "378e27ab-6b6c-4a46-9594-da4a938724e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3885921755.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_25202/3885921755.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    test = ['red' if i==1, 'green' if i ==2 else 'blue' for i in range(10)]\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "###Considerations = how many communities are found compared to healthy? which nodes are considered central now? any changes?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
